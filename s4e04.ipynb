{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Krt8Ii-eKyA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "import pickle\n",
        "from IPython.core.display import HTML\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_log_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_train = pd.read_csv('/kaggle/input/ps-4-e-2-abalone-dataset-from-uci/abalone.data', header=None)\n",
        "\n",
        "train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv')\n",
        "sample_submission = pd.read_csv('/kaggle/input/playground-series-s4e4/sample_submission.csv')"
      ],
      "metadata": {
        "id": "tTRB6EcXeeJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all properties on display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "train.head()"
      ],
      "metadata": {
        "id": "JU-crVUUdOto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(original_train.shape)\n",
        "original_train.columns.tolist()"
      ],
      "metadata": {
        "id": "t-ySl9_udQfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save original dataset into .csv\n",
        "original_train.columns = train.columns[1:]\n",
        "original_train.to_csv('orig.csv', index=False)\n",
        "original_train.tail()"
      ],
      "metadata": {
        "id": "8xShFzKtdTZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_id = test.id\n",
        "\n",
        "train.drop(columns='id', axis=1, inplace=True)\n",
        "test.drop(columns='id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "GRiiGoNI9eju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop_duplicates()\n",
        "\n",
        "# Check whether all duplicates were removed\n",
        "train_duplicates = train[train.duplicated()]\n",
        "print(len(train_duplicates))"
      ],
      "metadata": {
        "id": "uXgal44M9gt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train data: {train.shape}')\n",
        "print(f'Test data: {test.shape}\\n')\n",
        "\n",
        "train_data_percentage = np.round(train.shape[0] / (train.shape[0] + test.shape[0]), 4)\n",
        "print(f'Train data consists of {train_data_percentage * 100}% of all observations')\n",
        "print(f'Test data consists of {(1 - train_data_percentage) * 100}% of all observations')"
      ],
      "metadata": {
        "id": "F_MB86z99izm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe().T"
      ],
      "metadata": {
        "id": "CYK0-z729l4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TRAIN data\\n')\n",
        "print(f'{train.isna().sum()}\\n\\n\\n')\n",
        "\n",
        "print('TEST data\\n')\n",
        "print(test.isna().sum())"
      ],
      "metadata": {
        "id": "PW1M7QRnV5M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop_duplicates()\n",
        "\n",
        "# Check whether all duplicates were removed\n",
        "duplicates = train[train.duplicated()]\n",
        "len(duplicates)"
      ],
      "metadata": {
        "id": "H2p25jOaV6-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(train, drop_first=True, dtype=int)\n",
        "test = pd.get_dummies(test, drop_first=True, dtype=int)"
      ],
      "metadata": {
        "id": "WempgSmZV9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize': (20, 16)})\n",
        "X.hist(color='orange');"
      ],
      "metadata": {
        "id": "fRLpCw6xWCZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{train.Rings.value_counts()}\\n\\n')\n",
        "print(train.Rings.value_counts() / train.shape[0])"
      ],
      "metadata": {
        "id": "Tyx_MZXGWD0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the train data into X and y\n",
        "X = X.drop(['Rings'], axis=1)\n",
        "y = train.Rings\n",
        "\n",
        "# for column in X.columns.tolist():\n",
        "#     X[column] = X[column].apply(lambda x: (x - X[column].min()) / (X[column].max() - X[column].min()))\n",
        "\n",
        "# # Transform test data\n",
        "# for column in test.columns.tolist():\n",
        "#     test[column] = test[column].apply(lambda x: (x - test[column].min()) / (test[column].max() - test[column].min()))\n",
        "\n",
        "# X.hist(color='LightSeaGreen');"
      ],
      "metadata": {
        "id": "F5eHRcP1WGG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# I figured out best hyperparameters previously\n",
        "best_forest = RandomForestRegressor(\n",
        "    random_state=27,\n",
        ")\n",
        "\n",
        "best_forest.fit(X, y)\n",
        "importance = best_forest.feature_importances_\n",
        "\n",
        "feature_importance = pd.DataFrame(data=importance, index=X.columns, columns=['importance']) \\\n",
        "    .sort_values(ascending=True, by='importance')\n",
        "\n",
        "feature_importance.plot(kind='barh', figsize=(12, 8), color='orange');"
      ],
      "metadata": {
        "id": "pzGDtqJdWQGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.columns)"
      ],
      "metadata": {
        "id": "xoR3TIcKhBeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "numeric_columns_train = X.select_dtypes(include=np.number)\n",
        "corr_train = numeric_columns_train.corr(method='pearson')\n",
        "mask_train = np.triu(np.ones_like(corr_train))\n",
        "sns.heatmap(corr_train, annot=True, fmt='.2f', mask=mask_train, cmap='Spectral', cbar=None, linewidth=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jrQPUVBHhEGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop(['Diameter', 'Whole weight.2'], axis=1)\n",
        "test = test.drop(['Diameter', 'Whole weight.2'], axis=1)"
      ],
      "metadata": {
        "id": "QhjbHC2nhF7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "numeric_columns_train = X.select_dtypes(include=np.number)\n",
        "corr_train = numeric_columns_train.corr(method='pearson')\n",
        "mask_train = np.triu(np.ones_like(corr_train))\n",
        "sns.heatmap(corr_train, annot=True, fmt='.2f', mask=mask_train, cmap='coolwarm', cbar=None, linewidth=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Sq1DLNUGsm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27)"
      ],
      "metadata": {
        "id": "ssR3-ZanGttP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# def objective(trial):\n",
        "#     model = RandomForestRegressor(\n",
        "#         n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "# #         criterion=trial.suggest_categorical(\"criterion\", ['poisson', 'absolute_error', 'friedman_mse', 'squared_error']),\n",
        "#         min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 100),\n",
        "#         max_depth=trial.suggest_int(\"max_depth\", 1, 100),\n",
        "#         min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 100),\n",
        "#         random_state=27\n",
        "#     )\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     return np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# sampler = TPESampler(seed=27)\n",
        "# study = optuna.create_study(study_name=\"random_forest\", direction=\"maximize\", sampler=sampler)\n",
        "# study.optimize(objective, n_trials=10)\n",
        "\n",
        "# print(\"Number of finished trials: \", len(study.trials))\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(\"  Value: \", trial.value)\n",
        "# print(\"  Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f\"    {key}: {value}\")\n",
        "# print()\n",
        "\n",
        "\"\"\"\n",
        "Number of finished trials:  10\n",
        "Best trial:\n",
        "  Value:  0.164014686713176\n",
        "  Params:\n",
        "    n_estimators: 544\n",
        "    min_samples_leaf: 60\n",
        "    max_depth: 8\n",
        "    min_samples_split: 13\n",
        "\n",
        "CPU times: user 6min 35s, sys: 276 ms, total: 6min 35s\n",
        "Wall time: 6min 35s\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8g-ffZSfGx1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# def objective(trial):\n",
        "#     model = XGBRegressor(\n",
        "#         max_depth=trial.suggest_int('max_depth', 1, 100),\n",
        "#         learning_rate=trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
        "#         n_estimators=trial.suggest_int('n_estimators', 50, 1000),\n",
        "#         min_child_weight=trial.suggest_int('min_child_weight', 1, 10),\n",
        "#         gamma=trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
        "#         subsample=trial.suggest_float('subsample', 0.01, 1.0, log=True),\n",
        "#         colsample_bytree=trial.suggest_float('colsample_bytree', 0.01, 1.0, log=True),\n",
        "#         reg_alpha=trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
        "#         reg_lambda=trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
        "#         use_label_encoder=False,\n",
        "#         random_state=27\n",
        "#     )\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     try:\n",
        "#         return np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "#     except Exception as e:\n",
        "#         print(e)\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# sampler = TPESampler(seed=27)\n",
        "# study = optuna.create_study(study_name=\"xgb\", direction=\"maximize\", sampler=sampler)\n",
        "# study.optimize(objective, n_trials=20)\n",
        "\n",
        "# print(\"Number of finished trials: \", len(study.trials))\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(\"  Value: \", trial.value)\n",
        "# print(\"  Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f\"    {key}: {value}\")\n",
        "# print()\n",
        "\n",
        "\"\"\"\n",
        "Number of finished trials:  1\n",
        "Best trial:\n",
        "  Value:  0.1775845058982026\n",
        "  Params:\n",
        "    max_depth: 43\n",
        "    learning_rate: 0.42576257222865277\n",
        "    n_estimators: 749\n",
        "    min_child_weight: 9\n",
        "    gamma: 1.1669337024772915e-05\n",
        "    subsample: 0.9097315662154742\n",
        "    colsample_bytree: 0.6114890625963008\n",
        "    reg_alpha: 4.761254082318455e-07\n",
        "    reg_lambda: 0.008602430632882225\n",
        "\n",
        "CPU times: user 24.5 s, sys: 667 ms, total: 25.2 s\n",
        "Wall time: 25.2 s\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "69OAKfBMavoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}