{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### First glance"
      ],
      "metadata": {
        "id": "oWKCmd9cUrlz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Krt8Ii-eKyA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "import pickle\n",
        "from IPython.core.display import HTML\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_log_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_train = pd.read_csv('/kaggle/input/ps-4-e-2-abalone-dataset-from-uci/abalone.data', header=None)\n",
        "\n",
        "train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv')\n",
        "sample_submission = pd.read_csv('/kaggle/input/playground-series-s4e4/sample_submission.csv')"
      ],
      "metadata": {
        "id": "tTRB6EcXeeJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all properties on display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "train.head()"
      ],
      "metadata": {
        "id": "JU-crVUUdOto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(original_train.shape)\n",
        "original_train.columns.tolist()"
      ],
      "metadata": {
        "id": "t-ySl9_udQfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save original dataset into .csv\n",
        "original_train.columns = train.columns[1:]\n",
        "original_train.to_csv('orig.csv', index=False)\n",
        "original_train.tail()"
      ],
      "metadata": {
        "id": "8xShFzKtdTZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_id = test.id\n",
        "\n",
        "train.drop(columns='id', axis=1, inplace=True)\n",
        "test.drop(columns='id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "GRiiGoNI9eju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop_duplicates()\n",
        "\n",
        "# Check whether all duplicates were removed\n",
        "train_duplicates = train[train.duplicated()]\n",
        "print(len(train_duplicates))"
      ],
      "metadata": {
        "id": "uXgal44M9gt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train data: {train.shape}')\n",
        "print(f'Test data: {test.shape}\\n')\n",
        "\n",
        "train_data_percentage = np.round(train.shape[0] / (train.shape[0] + test.shape[0]), 4)\n",
        "print(f'Train data consists of {train_data_percentage * 100}% of all observations')\n",
        "print(f'Test data consists of {(1 - train_data_percentage) * 100}% of all observations')"
      ],
      "metadata": {
        "id": "F_MB86z99izm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe().T"
      ],
      "metadata": {
        "id": "CYK0-z729l4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TRAIN data\\n')\n",
        "print(f'{train.isna().sum()}\\n\\n\\n')\n",
        "\n",
        "print('TEST data\\n')\n",
        "print(test.isna().sum())"
      ],
      "metadata": {
        "id": "PW1M7QRnV5M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop_duplicates()\n",
        "\n",
        "# Check whether all duplicates were removed\n",
        "duplicates = train[train.duplicated()]\n",
        "len(duplicates)"
      ],
      "metadata": {
        "id": "H2p25jOaV6-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(train, drop_first=True, dtype=int)\n",
        "test = pd.get_dummies(test, drop_first=True, dtype=int)"
      ],
      "metadata": {
        "id": "WempgSmZV9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize': (20, 16)})\n",
        "X.hist(color='orange');"
      ],
      "metadata": {
        "id": "fRLpCw6xWCZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{train.Rings.value_counts()}\\n\\n')\n",
        "print(train.Rings.value_counts() / train.shape[0])"
      ],
      "metadata": {
        "id": "Tyx_MZXGWD0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the train data into X and y\n",
        "X = X.drop(['Rings'], axis=1)\n",
        "y = train.Rings\n",
        "\n",
        "# for column in X.columns.tolist():\n",
        "#     X[column] = X[column].apply(lambda x: (x - X[column].min()) / (X[column].max() - X[column].min()))\n",
        "\n",
        "# # Transform test data\n",
        "# for column in test.columns.tolist():\n",
        "#     test[column] = test[column].apply(lambda x: (x - test[column].min()) / (test[column].max() - test[column].min()))\n",
        "\n",
        "# X.hist(color='LightSeaGreen');"
      ],
      "metadata": {
        "id": "F5eHRcP1WGG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# I figured out best hyperparameters previously\n",
        "best_forest = RandomForestRegressor(\n",
        "    random_state=27,\n",
        ")\n",
        "\n",
        "best_forest.fit(X, y)\n",
        "importance = best_forest.feature_importances_\n",
        "\n",
        "feature_importance = pd.DataFrame(data=importance, index=X.columns, columns=['importance']) \\\n",
        "    .sort_values(ascending=True, by='importance')\n",
        "\n",
        "feature_importance.plot(kind='barh', figsize=(12, 8), color='orange');"
      ],
      "metadata": {
        "id": "pzGDtqJdWQGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.columns)"
      ],
      "metadata": {
        "id": "xoR3TIcKhBeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "numeric_columns_train = X.select_dtypes(include=np.number)\n",
        "corr_train = numeric_columns_train.corr(method='pearson')\n",
        "mask_train = np.triu(np.ones_like(corr_train))\n",
        "sns.heatmap(corr_train, annot=True, fmt='.2f', mask=mask_train, cmap='Spectral', cbar=None, linewidth=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jrQPUVBHhEGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop(['Diameter', 'Whole weight.2'], axis=1)\n",
        "test = test.drop(['Diameter', 'Whole weight.2'], axis=1)"
      ],
      "metadata": {
        "id": "QhjbHC2nhF7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "numeric_columns_train = X.select_dtypes(include=np.number)\n",
        "corr_train = numeric_columns_train.corr(method='pearson')\n",
        "mask_train = np.triu(np.ones_like(corr_train))\n",
        "sns.heatmap(corr_train, annot=True, fmt='.2f', mask=mask_train, cmap='coolwarm', cbar=None, linewidth=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Sq1DLNUGsm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27)"
      ],
      "metadata": {
        "id": "ssR3-ZanGttP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# def objective(trial):\n",
        "#     model = RandomForestRegressor(\n",
        "#         n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "# #         criterion=trial.suggest_categorical(\"criterion\", ['poisson', 'absolute_error', 'friedman_mse', 'squared_error']),\n",
        "#         min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 100),\n",
        "#         max_depth=trial.suggest_int(\"max_depth\", 1, 100),\n",
        "#         min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 100),\n",
        "#         random_state=27\n",
        "#     )\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     return np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# sampler = TPESampler(seed=27)\n",
        "# study = optuna.create_study(study_name=\"random_forest\", direction=\"maximize\", sampler=sampler)\n",
        "# study.optimize(objective, n_trials=10)\n",
        "\n",
        "# print(\"Number of finished trials: \", len(study.trials))\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(\"  Value: \", trial.value)\n",
        "# print(\"  Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f\"    {key}: {value}\")\n",
        "# print()\n",
        "\n",
        "\"\"\"\n",
        "Number of finished trials:  10\n",
        "Best trial:\n",
        "  Value:  0.164014686713176\n",
        "  Params:\n",
        "    n_estimators: 544\n",
        "    min_samples_leaf: 60\n",
        "    max_depth: 8\n",
        "    min_samples_split: 13\n",
        "\n",
        "CPU times: user 6min 35s, sys: 276 ms, total: 6min 35s\n",
        "Wall time: 6min 35s\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8g-ffZSfGx1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# def objective(trial):\n",
        "#     model = XGBRegressor(\n",
        "#         max_depth=trial.suggest_int('max_depth', 1, 100),\n",
        "#         learning_rate=trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
        "#         n_estimators=trial.suggest_int('n_estimators', 50, 1000),\n",
        "#         min_child_weight=trial.suggest_int('min_child_weight', 1, 10),\n",
        "#         gamma=trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
        "#         subsample=trial.suggest_float('subsample', 0.01, 1.0, log=True),\n",
        "#         colsample_bytree=trial.suggest_float('colsample_bytree', 0.01, 1.0, log=True),\n",
        "#         reg_alpha=trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
        "#         reg_lambda=trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
        "#         use_label_encoder=False,\n",
        "#         random_state=27\n",
        "#     )\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     try:\n",
        "#         return np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "#     except Exception as e:\n",
        "#         print(e)\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# sampler = TPESampler(seed=27)\n",
        "# study = optuna.create_study(study_name=\"xgb\", direction=\"maximize\", sampler=sampler)\n",
        "# study.optimize(objective, n_trials=20)\n",
        "\n",
        "# print(\"Number of finished trials: \", len(study.trials))\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(\"  Value: \", trial.value)\n",
        "# print(\"  Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f\"    {key}: {value}\")\n",
        "# print()\n",
        "\n",
        "\"\"\"\n",
        "Number of finished trials:  1\n",
        "Best trial:\n",
        "  Value:  0.1775845058982026\n",
        "  Params:\n",
        "    max_depth: 43\n",
        "    learning_rate: 0.42576257222865277\n",
        "    n_estimators: 749\n",
        "    min_child_weight: 9\n",
        "    gamma: 1.1669337024772915e-05\n",
        "    subsample: 0.9097315662154742\n",
        "    colsample_bytree: 0.6114890625963008\n",
        "    reg_alpha: 4.761254082318455e-07\n",
        "    reg_lambda: 0.008602430632882225\n",
        "\n",
        "CPU times: user 24.5 s, sys: 667 ms, total: 25.2 s\n",
        "Wall time: 25.2 s\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "69OAKfBMavoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# def objective(trial):\n",
        "#     model = CatBoostRegressor(\n",
        "#         iterations=trial.suggest_int(\"iterations\", 100, 1000),\n",
        "#         learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
        "#         colsample_bylevel=trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
        "#         min_data_in_leaf=trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "#         depth=trial.suggest_int(\"depth\", 4, 16),\n",
        "#         l2_leaf_reg=trial.suggest_float(\"l2_leaf_reg\", 1e-8, 100.0, log=True),\n",
        "#         verbose=False,\n",
        "#         random_state=27\n",
        "#     )\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     return np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# sampler = TPESampler(seed=27)\n",
        "# study = optuna.create_study(study_name=\"catboost\", direction=\"maximize\", sampler=sampler)\n",
        "# study.optimize(objective, n_trials=20)\n",
        "\n",
        "# print(\"Number of finished trials: \", len(study.trials))\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(\"  Value: \", trial.value)\n",
        "# print(\"  Params: \")\n",
        "\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f\"    {key}: {value}\")\n",
        "# print()\n",
        "\n",
        "\"\"\"\n",
        "Number of finished trials:  20\n",
        "Best trial:\n",
        "  Value:  0.27250015755480833\n",
        "  Params:\n",
        "    iterations: 101\n",
        "    learning_rate: 0.0010172906333606835\n",
        "    colsample_bylevel: 0.4796381789116622\n",
        "    min_data_in_leaf: 42\n",
        "    depth: 13\n",
        "    l2_leaf_reg: 2.895211427077531e-08\n",
        "\n",
        "CPU times: user 18min 10s, sys: 9min 21s, total: 27min 31s\n",
        "Wall time: 13min 5s\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "B-L2DJuJa0KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# def objective(trial):\n",
        "#     model = LGBMRegressor(\n",
        "#         n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "#         max_depth=trial.suggest_int(\"max_depth\", 1, 100),\n",
        "#         learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
        "#         verbosity=-1,\n",
        "#         boosting_type=trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
        "#         num_leaves=trial.suggest_int('num_leaves', 2, 256),\n",
        "#         min_child_samples=trial.suggest_int('min_child_samples', 5, 100),\n",
        "#         random_state=27\n",
        "#     )\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     return np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# sampler = TPESampler(seed=27)\n",
        "# study = optuna.create_study(study_name=\"lgbm\", direction=\"maximize\", sampler=sampler)\n",
        "# study.optimize(objective, n_trials=20)\n",
        "\n",
        "# print(\"Number of finished trials: \", len(study.trials))\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(\"  Value: \", trial.value)\n",
        "# print(\"  Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f\"    {key}: {value}\")\n",
        "# print()\n",
        "\n",
        "\"\"\"\n",
        "Number of finished trials:  20\n",
        "Best trial:\n",
        "  Value:  0.9971664373669932\n",
        "  Params:\n",
        "    n_estimators: 676\n",
        "    max_depth: 100\n",
        "    learning_rate: 0.0010257989336468524\n",
        "    boosting_type: dart\n",
        "    num_leaves: 37\n",
        "    min_child_samples: 22\n",
        "\n",
        "CPU times: user 38min 41s, sys: 5.25 s, total: 38min 47s\n",
        "Wall time: 38min 50s\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KBdA8mobLyWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('XGBoost', XGBRegressor(\n",
        "        n_estimators=395,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.01,\n",
        "        random_state=27\n",
        "    )),\n",
        "    ('LightGBM', LGBMRegressor(\n",
        "        n_estimators=676,\n",
        "        max_depth=100,\n",
        "        learning_rate=0.0010257989336468524,\n",
        "        boosting_type='dart',\n",
        "        num_leaves=37,\n",
        "        min_child_samples=22,\n",
        "        random_state=27\n",
        "    )),\n",
        "    ('Catboost', CatBoostRegressor(\n",
        "        iterations=101,\n",
        "        learning_rate=0.0010172906333606835,\n",
        "        colsample_bylevel=0.4796381789116622,\n",
        "        min_data_in_leaf=42,\n",
        "        depth=13,\n",
        "        l2_leaf_reg=2.895211427077531e-08,\n",
        "        random_state=27\n",
        "    )),\n",
        "    ('Random_forest', RandomForestRegressor(\n",
        "        n_estimators=544,\n",
        "        min_samples_leaf=60,\n",
        "        max_depth=8,\n",
        "        min_samples_split=13,\n",
        "        random_state=27\n",
        "    ))\n",
        "]"
      ],
      "metadata": {
        "id": "M-Eex9mdL3ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_model = XGBRegressor(\n",
        "    n_estimators=395,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.01,\n",
        "    random_state=27\n",
        ")"
      ],
      "metadata": {
        "id": "cCYkr8Gk4LHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "RandomForestRegressor(\n",
        "    n_estimators=544,\n",
        "    min_samples_leaf=60,\n",
        "    max_depth=8,\n",
        "    min_samples_split=13,\n",
        "    random_state=27\n",
        ")\n",
        "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
        "stacking_model.fit(X, y)"
      ],
      "metadata": {
        "id": "_WAO-6A14NCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_val = stacking_model.predict(X_val)\n",
        "\n",
        "rmsle_val = np.sqrt(mean_squared_log_error(y_val, y_pred_val))\n",
        "print(f\"Validation Root mean squared logarithmic error regression loss: {rmsle_val:.8f}\")"
      ],
      "metadata": {
        "id": "0a4iG6YCvBk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = stacking_model.predict(test)\n",
        "y_pred_test[:10]"
      ],
      "metadata": {
        "id": "B5ZQCGIrvE2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    'id': sample_submission.id,\n",
        "    'Rings': y_pred_test\n",
        "})\n",
        "\n",
        "submission.to_csv('Kapturov_S4E4_submission.csv', index=False)\n",
        "submission.head(10)"
      ],
      "metadata": {
        "id": "DnTZWDbLUTn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(stacking_model, open(\"Kapturov_stacking_model.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "fe1UTfLZUWHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second approach"
      ],
      "metadata": {
        "id": "5_ucE47MUnLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import preprocessing\n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Lambda, Concatenate, Add, BatchNormalization, LeakyReLU,ELU\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "EU4hAPIsUqSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\n",
        "df_test  = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv')\n",
        "df_sub = pd.read_csv('/kaggle/input/playground-series-s4e4/sample_submission.csv')"
      ],
      "metadata": {
        "id": "KsCjBfpSUz2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df_train['Sex_encoded'] = label_encoder.fit_transform(df_train['Sex'])\n",
        "df_test['Sex_encoded']  = label_encoder.fit_transform(df_test['Sex'])\n",
        "df_train.drop(columns=['Sex'], inplace=True)\n",
        "df_test.drop(columns=['Sex'], inplace=True)"
      ],
      "metadata": {
        "id": "w-ARaLUHZedV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.drop(columns=['id'], inplace=True)\n",
        "df_test.drop(columns=['id'], inplace=True)"
      ],
      "metadata": {
        "id": "AfG8S4uDZg0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.scatterplot(data=df_train, x='Shell weight', y='Rings', hue='Sex', palette='Set1')\n",
        "plt.title('Rings vs. Shell Weight by Sex')\n",
        "plt.xlabel('Shell Weight')\n",
        "plt.ylabel('Rings')\n",
        "plt.legend(title='Sex')\n",
        "plt.gcf().set_facecolor('#DFFF00')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ojsmkyd9Zh0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "sns.boxplot(data=df_train, x='Sex', y='Rings', palette='Set1')\n",
        "plt.title('Age Distribution (Rings) by Sex')\n",
        "plt.xlabel('Sex')\n",
        "plt.ylabel('Rings')\n",
        "plt.gcf().set_facecolor('#FF00FF')\n",
        "plt.xticks(ticks=[0, 1, 2], labels=['Male', 'Female', 'Infant'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8JT0_JKifW8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = df_train.corr()\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='viridis', fmt=\".2f\")\n",
        "plt.gcf().set_facecolor('#00FFFF')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vGwCoE4kfZLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1', 'Whole weight.2', 'Shell weight']\n",
        "num_plots = len(numerical_features)\n",
        "rows = 3\n",
        "cols = math.ceil(num_plots / rows)\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    row = i // cols\n",
        "    col = i % cols\n",
        "    ax = axes[row, col]\n",
        "    sns.histplot(df_train[feature], kde=True, ax=ax)\n",
        "    ax.set_title(f'Distribution of {feature}')\n",
        "    ax.set_xlabel(feature)\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "for i in range(num_plots, rows * cols):\n",
        "    row = i // cols\n",
        "    col = i % cols\n",
        "    fig.delaxes(axes[row, col])\n",
        "\n",
        "plt.gcf().set_facecolor('#FFF8DC')  # Set background color of the entire figure\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3UlLrYZrM7vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "sns.boxplot(data=df_train[['Length', 'Diameter', 'Height', 'Whole weight', 'Shell weight']], orient='h', palette='Set3')\n",
        "plt.title('Boxplot of Numerical Features')\n",
        "plt.gcf().set_facecolor('#008080')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LbpSlStnM-VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_counts = df_train['Sex'].value_counts()\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.axis('equal')\n",
        "plt.title('Distribution of Gender')\n",
        "plt.gcf().set_facecolor('#00FF00')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QAN7bUkUNKF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}