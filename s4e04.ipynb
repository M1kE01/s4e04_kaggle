{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Krt8Ii-eKyA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "import pickle\n",
        "from IPython.core.display import HTML\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_log_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_train = pd.read_csv('/kaggle/input/ps-4-e-2-abalone-dataset-from-uci/abalone.data', header=None)\n",
        "\n",
        "train = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/playground-series-s4e4/test.csv')\n",
        "sample_submission = pd.read_csv('/kaggle/input/playground-series-s4e4/sample_submission.csv')"
      ],
      "metadata": {
        "id": "tTRB6EcXeeJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all properties on display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "train.head()"
      ],
      "metadata": {
        "id": "JU-crVUUdOto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(original_train.shape)\n",
        "original_train.columns.tolist()"
      ],
      "metadata": {
        "id": "t-ySl9_udQfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save original dataset into .csv\n",
        "original_train.columns = train.columns[1:]\n",
        "original_train.to_csv('orig.csv', index=False)\n",
        "original_train.tail()"
      ],
      "metadata": {
        "id": "8xShFzKtdTZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_id = test.id\n",
        "\n",
        "train.drop(columns='id', axis=1, inplace=True)\n",
        "test.drop(columns='id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "GRiiGoNI9eju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop_duplicates()\n",
        "\n",
        "# Check whether all duplicates were removed\n",
        "train_duplicates = train[train.duplicated()]\n",
        "print(len(train_duplicates))"
      ],
      "metadata": {
        "id": "uXgal44M9gt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train data: {train.shape}')\n",
        "print(f'Test data: {test.shape}\\n')\n",
        "\n",
        "train_data_percentage = np.round(train.shape[0] / (train.shape[0] + test.shape[0]), 4)\n",
        "print(f'Train data consists of {train_data_percentage * 100}% of all observations')\n",
        "print(f'Test data consists of {(1 - train_data_percentage) * 100}% of all observations')"
      ],
      "metadata": {
        "id": "F_MB86z99izm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe().T"
      ],
      "metadata": {
        "id": "CYK0-z729l4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TRAIN data\\n')\n",
        "print(f'{train.isna().sum()}\\n\\n\\n')\n",
        "\n",
        "print('TEST data\\n')\n",
        "print(test.isna().sum())"
      ],
      "metadata": {
        "id": "PW1M7QRnV5M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop_duplicates()\n",
        "\n",
        "# Check whether all duplicates were removed\n",
        "duplicates = train[train.duplicated()]\n",
        "len(duplicates)"
      ],
      "metadata": {
        "id": "H2p25jOaV6-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(train, drop_first=True, dtype=int)\n",
        "test = pd.get_dummies(test, drop_first=True, dtype=int)"
      ],
      "metadata": {
        "id": "WempgSmZV9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize': (20, 16)})\n",
        "X.hist(color='orange');"
      ],
      "metadata": {
        "id": "fRLpCw6xWCZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{train.Rings.value_counts()}\\n\\n')\n",
        "print(train.Rings.value_counts() / train.shape[0])"
      ],
      "metadata": {
        "id": "Tyx_MZXGWD0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the train data into X and y\n",
        "X = X.drop(['Rings'], axis=1)\n",
        "y = train.Rings\n",
        "\n",
        "# for column in X.columns.tolist():\n",
        "#     X[column] = X[column].apply(lambda x: (x - X[column].min()) / (X[column].max() - X[column].min()))\n",
        "\n",
        "# # Transform test data\n",
        "# for column in test.columns.tolist():\n",
        "#     test[column] = test[column].apply(lambda x: (x - test[column].min()) / (test[column].max() - test[column].min()))\n",
        "\n",
        "# X.hist(color='LightSeaGreen');"
      ],
      "metadata": {
        "id": "F5eHRcP1WGG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# I figured out best hyperparameters previously\n",
        "best_forest = RandomForestRegressor(\n",
        "    random_state=27,\n",
        ")\n",
        "\n",
        "best_forest.fit(X, y)\n",
        "importance = best_forest.feature_importances_\n",
        "\n",
        "feature_importance = pd.DataFrame(data=importance, index=X.columns, columns=['importance']) \\\n",
        "    .sort_values(ascending=True, by='importance')\n",
        "\n",
        "feature_importance.plot(kind='barh', figsize=(12, 8), color='orange');"
      ],
      "metadata": {
        "id": "pzGDtqJdWQGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.columns)"
      ],
      "metadata": {
        "id": "xoR3TIcKhBeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "numeric_columns_train = X.select_dtypes(include=np.number)\n",
        "corr_train = numeric_columns_train.corr(method='pearson')\n",
        "mask_train = np.triu(np.ones_like(corr_train))\n",
        "sns.heatmap(corr_train, annot=True, fmt='.2f', mask=mask_train, cmap='Spectral', cbar=None, linewidth=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jrQPUVBHhEGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop(['Diameter', 'Whole weight.2'], axis=1)\n",
        "test = test.drop(['Diameter', 'Whole weight.2'], axis=1)"
      ],
      "metadata": {
        "id": "QhjbHC2nhF7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "numeric_columns_train = X.select_dtypes(include=np.number)\n",
        "corr_train = numeric_columns_train.corr(method='pearson')\n",
        "mask_train = np.triu(np.ones_like(corr_train))\n",
        "sns.heatmap(corr_train, annot=True, fmt='.2f', mask=mask_train, cmap='coolwarm', cbar=None, linewidth=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Sq1DLNUGsm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27)"
      ],
      "metadata": {
        "id": "ssR3-ZanGttP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}